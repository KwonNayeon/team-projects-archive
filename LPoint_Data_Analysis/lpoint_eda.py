# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hnHsNqHh-chgybhXI2MR-r_TjN6y3Jaz
"""

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import os
import time
from datetime import datetime, date
import matplotlib.font_manager as fm
from google.colab import drive

# Mount Google Drive
drive.mount('/content/gdrive')

# Define paths
DATA_PATH = "/content/gdrive/Shareddrives/22SummerProjects/LPoint/Data/"

# Load datasets
demo = pd.read_csv(f'{DATA_PATH}LPOINT_BIG_COMP_01_DEMO.csv')
PDDE = pd.read_csv(f'{DATA_PATH}LPOINT_BIG_COMP_02_PDDE.csv')
PD_CLAC = pd.read_csv(f'{DATA_PATH}LPOINT_BIG_COMP_04_PD_CLAC.csv')
BR = pd.read_csv(f'{DATA_PATH}LPOINT_BIG_COMP_05_BR.csv')
COP = pd.read_csv(f'{DATA_PATH}LPOINT_BIG_COMP_03_COP_U.csv')

# Install and set up Nanum font
!apt-get update -qq
!apt-get install fonts-nanum* -qq

path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'
font_name = fm.FontProperties(fname=path, size=10).get_name()
plt.rc('font', family=font_name)
mpl.rc('axes', unicode_minus=False)

# Function to check current font settings
def current_font():
    print(f"설정 폰트 글꼴: {plt.rcParams['font.family']}, 설정 폰트 사이즈: {plt.rcParams['font.size']}")

current_font()

# Test plot to verify font settings
plt.plot([x for x in range(0, 10)], [(3*y**2)+2 for y in range(0, 10)])
plt.title("예제", fontsize=13)
plt.xlabel("x축", fontsize=12)
plt.xticks(np.arange(0, 10, 1), ['하나', '둘', '셋', '넷', '다섯', '여섯', '일곱', '여덟', '아홉', '열'], fontsize=12, rotation=45)
plt.ylabel("y축", fontsize=12)
plt.show()

# Merge Multiple Dataframes (demo, PDDE, PD_CLAC) with Pandas
sample2 = pd.merge(pd.merge(demo, PDDE, on='cust'), PD_CLAC, on='pd_c')
print(sample2)

# Outer join of PDDE and COP
df1 = pd.merge(PDDE, COP, how='outer')
print(df1)

# Left join df1 with demo and PD_CLAC
df2 = df1.merge(demo, how='left', on='cust').merge(PD_CLAC, how='left', on='pd_c')
print(df2)

# Left join df2 with BR
df3 = pd.merge(left=df2, right=BR, how='left', on=['br_c', 'cop_c', 'zon_hlv'], sort=False)
print(df3)

# Function to check for missing values
def check_missing_col(dataframe):
    missing_col = []
    for col in dataframe.columns:
        missing_values = dataframe[col].isna().sum()
        if missing_values > 0:
            print(f'결측치가 있는 컬럼은: {col}입니다')
            print(f'해당 컬럼에 총 {missing_values}개의 결측치가 존재합니다.')
            missing_col.append([col, dataframe[col].dtype])
    if not missing_col:
        print('결측치가 존재하지 않습니다')
    return missing_col

missing_col = check_missing_col(df3)

# Regional classification
print(pd.crosstab(index=df3['zon_hlv'], columns='count'))
print(pd.crosstab(index=df3['zon_mcls'], columns='count'))

# Convert floats to strings
df3['chnl_dv'] = df3['chnl_dv'].astype(str)

# Describe the DataFrame, including object type columns
print(df3.describe(include='O'))
print(df3.describe())

# Cross-tabulation for gender and age groups
print(pd.crosstab(index=df3['chnl_dv'], columns='count'))

# Summary statistics for purchase amounts
print(df3[["buy_am"]].describe())

# Average spending money for male versus female
print(df3[["ma_fem_dv", "buy_am"]].groupby("ma_fem_dv").mean())

# Mean spending money for each sex and age combination
print(df3.groupby(["ma_fem_dv", "ages"])["buy_am"].mean())

# Change directory
os.chdir("/content/gdrive/Shareddrives/22SummerProjects/LPoint/Plots/")

# Visualize age distribution
sns.catplot(x="ages", kind="count", data=df3)

# Visualize gender distribution by age
sns.countplot(x="ages", hue="ma_fem_dv", data=df3)

# Visualize gender distribution by channel and age
sns.catplot(x="ages", hue="ma_fem_dv", col="chnl_dv", data=df3, kind="count", height=4, aspect=.7)

# Count occurrences of each category in 'cop_c'
print(df3['cop_c'].value_counts())

# Visualize purchase time distribution by channel
sns.countplot(x="de_hr", hue="chnl_dv", data=df3)

# Variable type separation
categorical = ['cust', 'ma_fem_dv', 'ages', 'zon_hlv_x', 'rct_no', 'br_c', 'pd_c', 'clac_hlv_nm', 'zon_hlv_y']
quantitative = ['chnl_dv', 'de_dt', 'de_hr', 'buy_am', 'buy_ct']

print(f'카테고리형(정성적) columns : {len(categorical)} 개')
print(f'수치형(정량적) columns : {len(quantitative)} 개')

# Create new date-related features
df3['new_date'] = pd.to_datetime(df3['de_dt'].astype(str), format='%Y%m%d')
df3['new_year'] = df3['new_date'].dt.year
df3['new_month'] = df3['new_date'].dt.month
df3['new_day'] = df3['new_date'].dt.day
df3['new_week'] = df3['new_date'].dt.day_name()

print(df3[['new_date', 'new_year', 'new_month', 'new_day', 'new_week']])

# Pivot tables for sum of purchases by day of the week
print(pd.pivot_table(data=df3, index='new_week', values='buy_ct', aggfunc='sum'))
print(pd.pivot_table(data=df3, index='new_week', values='buy_am', aggfunc='sum'))

# Visualize purchase amount by day of the week
sns.barplot(data=df3, x='new_week', y='buy_am')
plt.savefig(f'./days_of_the_week1.jpg', dpi=300)

# Visualize online/offline purchase amount by day of the week
sns.barplot(x="new_week", y="buy_am", hue="chnl_dv", data=df3)
plt.savefig(f'./days_of_the_week2.jpg', dpi=300)

# Dictionary mapping weekdays to weekend/weekday categories
remap_cat_dict = {
    "Monday": 0,
    "Tuesday": 0,
    "Wednesday": 0,
    "Thursday": 0,
    "Friday": 0,
    "Saturday": 1,
    "Sunday": 1,
}

# df3['new_week'] = df3.new_week.map(remap_cat_dict).astype('category')

# Product category distribution by large category
sns.catplot(x="clac_hlv_nm", kind="count", data=df3)

# Notes:
# 1. Normalize purchase amount/frequency by category (log normalization, Gaussian normalization)
# 2. Outlier detection
# 3. XGBoost
# 4. Dimensionality reduction with PCA -> Sales amount prediction (regression)